{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data import"
      ],
      "metadata": {
        "id": "0uglUbtkIqkW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj1xOFaaIe-1",
        "outputId": "8471d8d7-29d5-41e3-d638-0f983ed000ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (1.0.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/dogcdt/synapse?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 607M/607M [00:27<00:00, 22.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"dogcdt/synapse\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# losses and metrics"
      ],
      "metadata": {
        "id": "OOQD0qZHIu1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install medpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cEX-YQTJ11H",
        "outputId": "8bf426de-3aad-43e8-d036-bab28a48d744"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medpy\n",
            "  Downloading medpy-0.5.2.tar.gz (156 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/156.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.3/156.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.12/dist-packages (from medpy) (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from medpy) (2.0.2)\n",
            "Collecting SimpleITK>=2.1 (from medpy)\n",
            "  Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.4 kB)\n",
            "Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.5.2-py3-none-any.whl size=224710 sha256=da16090ccfde3486d5c04656a7529e5d60e418ebf03adf23ff474e613a78081b\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/5a/f8/b3def53b9c2133d2f8698ea2173bb5df63bd8e761ce8e9aec9\n",
            "Successfully built medpy\n",
            "Installing collected packages: SimpleITK, medpy\n",
            "Successfully installed SimpleITK-2.5.3 medpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from medpy import metric\n",
        "from scipy.ndimage import zoom\n",
        "import torch.nn as nn\n",
        "import SimpleITK as sitk\n",
        "\n",
        "## metrics\n",
        "def calculate_metric_percase(pred, gt):\n",
        "    pred[pred > 0] = 1\n",
        "    gt[gt > 0] = 1\n",
        "    if pred.sum() > 0 and gt.sum()>0:\n",
        "        dice = metric.binary.dc(pred, gt)\n",
        "        hd95 = metric.binary.hd95(pred, gt)\n",
        "        jac = metric.binary.jc(pred, gt)\n",
        "        return dice, jac, hd95\n",
        "    elif pred.sum() > 0 and gt.sum()==0:\n",
        "        return 1, 1, 0\n",
        "    else:\n",
        "        return 0, 0, 0\n",
        "\n",
        "def multilabel_metric(pred, gt, num_classes):\n",
        "    gt = gt.squeeze(0)\n",
        "    metric_list = []\n",
        "    for i in range(1, num_classes):\n",
        "        metric_list.append(calculate_metric_percase(pred == i, gt == i))\n",
        "    return metric_list  # list, lenth=num_classes-1, 每个元素含有(x,y,z)\n",
        "\n",
        "# losses\n",
        "class BinaryDiceLoss(nn.Module):\n",
        "    def init(self):\n",
        "        super(BinaryDiceLoss, self).init()\n",
        "\n",
        "    def forward(self, input, targets):\n",
        "        # 获取每个批次的大小 N\n",
        "        N = targets.size()[0]\n",
        "        # 平滑变量\n",
        "        smooth = 1\n",
        "        # 将宽高 reshape 到同一纬度\n",
        "        input_flat = input.view(N, -1)\n",
        "        targets_flat = targets.view(N, -1)\n",
        "        # 计算交集\n",
        "        intersection = input_flat * targets_flat\n",
        "        N_dice_eff = (2 * intersection.sum(1) + smooth) / (input_flat.sum(1) + targets_flat.sum(1) + smooth)\n",
        "        # 计算一个批次中平均每张图的损失\n",
        "        loss = 1 - N_dice_eff.sum() / N\n",
        "        return loss\n",
        "\n",
        "\n",
        "class MultiClassDiceLoss(nn.Module):\n",
        "    def init(self, weight=None, ignore_index=None, **kwargs):\n",
        "        super(MultiClassDiceLoss, self).init()\n",
        "        self.weight = weight\n",
        "        self.ignore_index = ignore_index\n",
        "        self.kwargs = kwargs\n",
        "    def forward(self, input, target):\n",
        "        \"\"\"\n",
        "        input tesor of shape = (N, C, H, W)\n",
        "        target tensor of shape = (N, H, W)\n",
        "        \"\"\"\n",
        "        # 先将 target 进行 one-hot 处理，转换为 (N, C, H, W)\n",
        "        # target[target==255.] = 0.\n",
        "        nclass = input.shape[1]\n",
        "        target = F.one_hot(target.long(), nclass)\n",
        "        target = target.reshape(input.shape[0],input.shape[1],input.shape[2],-1)\n",
        "\n",
        "        assert input.shape == target.shape, \"predict & target shape do not match\"\n",
        "        binaryDiceLoss = BinaryDiceLoss()\n",
        "        total_loss = 0\n",
        "        # 归一化输出\n",
        "        logits = F.softmax(input, dim=1)\n",
        "        C = target.shape[1]\n",
        "        # 遍历 channel，得到每个类别的二分类 DiceLoss\n",
        "        for i in range(C):\n",
        "            dice_loss = binaryDiceLoss(logits[:, i], target[:, i])\n",
        "            total_loss += dice_loss\n",
        "            # 每个类别的平均 dice_loss\n",
        "        return total_loss / C"
      ],
      "metadata": {
        "id": "B8Y2K2IKIuQQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataset manipulation"
      ],
      "metadata": {
        "id": "M7t9JusGKO_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage import zoom\n",
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Augmentations\n",
        "# -------------------------\n",
        "def random_rot_flip(image, label):\n",
        "    k = np.random.randint(0, 4)\n",
        "    image = np.rot90(image, k)\n",
        "    label = np.rot90(label, k)\n",
        "    axis = np.random.randint(0, 2)\n",
        "    image = np.flip(image, axis=axis).copy()\n",
        "    label = np.flip(label, axis=axis).copy()\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def random_rotate(image, label):\n",
        "    angle = np.random.randint(-20, 20)\n",
        "    image = ndimage.rotate(image, angle, order=0, reshape=False)\n",
        "    label = ndimage.rotate(label, angle, order=0, reshape=False)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "class RandomGenerator(object):\n",
        "    def __init__(self, output_size):\n",
        "        self.output_size = output_size  # (H, W)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample[\"image\"], sample[\"label\"]\n",
        "\n",
        "        if random.random() > 0.5:\n",
        "            image, label = random_rot_flip(image, label)\n",
        "        elif random.random() > 0.5:\n",
        "            image, label = random_rotate(image, label)\n",
        "\n",
        "        x, y = image.shape\n",
        "        if (x != self.output_size[0]) or (y != self.output_size[1]):\n",
        "            image = zoom(image, (self.output_size[0] / x, self.output_size[1] / y), order=3)\n",
        "            label = zoom(label, (self.output_size[0] / x, self.output_size[1] / y), order=0)\n",
        "\n",
        "        image = torch.from_numpy(image.astype(np.float32)).unsqueeze(0)  # (1, H, W)\n",
        "        label = torch.from_numpy(label.astype(np.int64))                 # (H, W)\n",
        "        return {\"image\": image, \"label\": label}\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Dataset\n",
        "# -------------------------\n",
        "class Synapse_dataset(Dataset):\n",
        "    \"\"\"\n",
        "    Your structure:\n",
        "\n",
        "    /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/\n",
        "        train_npz/\n",
        "        test_vol_h5/   (or whatever your test folder is)\n",
        "    /root/lists_synapse/\n",
        "        train.txt\n",
        "        test_vol.txt\n",
        "\n",
        "    Train slices: <name>.npz with keys (image, label)\n",
        "    Test volumes: <name>.npy.h5 OR <name>.h5 OR <name>.n5 with datasets (image, label)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        versions_root=\"/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\",\n",
        "        split=\"train\",\n",
        "        transform=None,\n",
        "        list_dir=\"/root/lists_synapse\",\n",
        "        data_subdir=\"Synapse\",          # <-- IMPORTANT: your extra folder level\n",
        "        train_folder=\"train_npz\",\n",
        "        test_folder=\"test_vol_h5\",\n",
        "        train_list=\"train.txt\",\n",
        "        test_list=\"test_vol.txt\",\n",
        "        verbose=True,\n",
        "    ):\n",
        "        self.transform = transform\n",
        "        self.split = split.lower().strip()\n",
        "\n",
        "        versions_root = Path(versions_root).expanduser().resolve()\n",
        "        self.data_root = (versions_root / data_subdir).resolve()  # <-- /.../versions/1/Synapse\n",
        "\n",
        "        list_dir = Path(list_dir).expanduser()\n",
        "        self.list_dir = list_dir.resolve() if list_dir.is_absolute() else (self.data_root / list_dir).resolve()\n",
        "\n",
        "        self.train_dir = (self.data_root / train_folder).resolve()\n",
        "        self.test_dir = (self.data_root / test_folder).resolve()\n",
        "\n",
        "        list_file = self.list_dir / (train_list if self.split == \"train\" else test_list)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"VERSIONS ROOT:\", versions_root)\n",
        "            print(\"DATA ROOT    :\", self.data_root)\n",
        "            print(\"LIST DIR     :\", self.list_dir)\n",
        "            print(\"LIST FILE    :\", list_file)\n",
        "            print(\"TRAIN DIR    :\", self.train_dir)\n",
        "            print(\"TEST  DIR    :\", self.test_dir)\n",
        "\n",
        "        if not list_file.is_file():\n",
        "            raise FileNotFoundError(f\"Missing list file: {list_file}\")\n",
        "\n",
        "        self.sample_list = list_file.read_text().splitlines()\n",
        "\n",
        "        if self.split == \"train\" and not self.train_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Missing folder: {self.train_dir}\")\n",
        "        if self.split != \"train\" and not self.test_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Missing folder: {self.test_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_list)\n",
        "\n",
        "    def _resolve_train_path(self, name: str) -> Path:\n",
        "        return self.train_dir / f\"{name}.npz\"\n",
        "\n",
        "    def _resolve_test_path(self, name: str) -> Path:\n",
        "        candidates = [\n",
        "            self.test_dir / f\"{name}.npy.h5\",\n",
        "            self.test_dir / f\"{name}.h5\",\n",
        "            self.test_dir / f\"{name}.n5\",\n",
        "        ]\n",
        "        for p in candidates:\n",
        "            if p.is_file():\n",
        "                return p\n",
        "        return candidates[0]\n",
        "\n",
        "    def show_paths(self, max_items=20):\n",
        "        n = min(len(self.sample_list), max_items)\n",
        "        print(f\"Showing {n}/{len(self.sample_list)} paths for split='{self.split}'\")\n",
        "        for i in range(n):\n",
        "            name = self.sample_list[i].strip()\n",
        "            p = self._resolve_train_path(name) if self.split == \"train\" else self._resolve_test_path(name)\n",
        "            print(p, \"| exists =\", p.exists())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.sample_list[idx].strip()\n",
        "\n",
        "        if self.split == \"train\":\n",
        "            data_path = self._resolve_train_path(name)\n",
        "            if not data_path.is_file():\n",
        "                raise FileNotFoundError(f\"Missing train npz: {data_path}\")\n",
        "\n",
        "            data = np.load(str(data_path))\n",
        "            image, label = data[\"image\"], data[\"label\"]\n",
        "\n",
        "        else:\n",
        "            h5_path = self._resolve_test_path(name)\n",
        "            if not h5_path.is_file():\n",
        "                raise FileNotFoundError(\n",
        "                    \"Missing test volume. Tried: \"\n",
        "                    f\"{self.test_dir / (name + '.npy.h5')}, \"\n",
        "                    f\"{self.test_dir / (name + '.h5')}, \"\n",
        "                    f\"{self.test_dir / (name + '.n5')}\"\n",
        "                )\n",
        "\n",
        "            with h5py.File(str(h5_path), \"r\") as data:\n",
        "                image, label = data[\"image\"][:], data[\"label\"][:]\n",
        "\n",
        "        sample = {\"image\": image, \"label\": label}\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        sample[\"case_name\"] = name\n",
        "        return sample\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Quick local test\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    versions_root = \"/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\"\n",
        "    list_dir = \"/root/lists_synapse\"\n",
        "\n",
        "    ds_train = Synapse_dataset(versions_root=versions_root, split=\"train\", transform=None, list_dir=list_dir)\n",
        "    ds_train.show_paths(max_items=30)\n",
        "\n",
        "    ds_test = Synapse_dataset(versions_root=versions_root, split=\"test\", transform=None, list_dir=list_dir)\n",
        "    ds_test.show_paths(max_items=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqHdNPp2JrIw",
        "outputId": "28d63478-59da-424d-e7ce-c1a53a3b2fc5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VERSIONS ROOT: /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\n",
            "DATA ROOT    : /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse\n",
            "LIST DIR     : /root/lists_synapse\n",
            "LIST FILE    : /root/lists_synapse/train.txt\n",
            "TRAIN DIR    : /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz\n",
            "TEST  DIR    : /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5\n",
            "Showing 30/2211 paths for split='train'\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice000.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice001.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice002.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice003.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice004.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice005.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice006.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice007.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice008.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice009.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice010.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice011.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice012.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice013.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice014.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice015.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice016.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice017.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice018.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice019.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice020.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice021.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice022.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice023.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice024.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice025.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice026.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice027.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice028.npz | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz/case0031_slice029.npz | exists = True\n",
            "VERSIONS ROOT: /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\n",
            "DATA ROOT    : /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse\n",
            "LIST DIR     : /root/lists_synapse\n",
            "LIST FILE    : /root/lists_synapse/test_vol.txt\n",
            "TRAIN DIR    : /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz\n",
            "TEST  DIR    : /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5\n",
            "Showing 10/12 paths for split='test'\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5/case0008.npy.h5 | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5/case0022.npy.h5 | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5/case0038.npy.h5 | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5/case0036.npy.h5 | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5/case0032.npy.h5 | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5/case0002.npy.h5 | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5/case0029.npy.h5 | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5/case0003.npy.h5 | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5/case0001.npy.h5 | exists = True\n",
            "/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5/case0004.npy.h5 | exists = True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "https://github.com/Minerva-J/Pytorch-Segmentation-multi-models/blob/master/models/AttentionUnet/AttUnet.py\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(conv_block, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up_conv(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(up_conv, self).__init__()\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up(x)\n",
        "        return x\n",
        "\n",
        "class Attention_block(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super(Attention_block, self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "\n",
        "        return x * psi\n",
        "\n",
        "\n",
        "class U_Net(nn.Module):\n",
        "    def __init__(self, img_ch=3, num_class=9):\n",
        "        super(U_Net, self).__init__()\n",
        "\n",
        "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.Conv1 = conv_block(ch_in=img_ch, ch_out=64)\n",
        "        self.Conv2 = conv_block(ch_in=64, ch_out=128)\n",
        "        self.Conv3 = conv_block(ch_in=128, ch_out=256)\n",
        "        self.Conv4 = conv_block(ch_in=256, ch_out=512)\n",
        "        self.Conv5 = conv_block(ch_in=512, ch_out=1024)\n",
        "\n",
        "        self.Up5 = up_conv(ch_in=1024, ch_out=512)\n",
        "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
        "\n",
        "        self.Up4 = up_conv(ch_in=512, ch_out=256)\n",
        "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
        "\n",
        "        self.Up3 = up_conv(ch_in=256, ch_out=128)\n",
        "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
        "\n",
        "        self.Up2 = up_conv(ch_in=128, ch_out=64)\n",
        "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
        "\n",
        "        self.Conv_1x1 = nn.Conv2d(64, num_class, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoding path\n",
        "        x1 = self.Conv1(x)\n",
        "\n",
        "        x2 = self.Maxpool(x1)\n",
        "        x2 = self.Conv2(x2)\n",
        "\n",
        "        x3 = self.Maxpool(x2)\n",
        "        x3 = self.Conv3(x3)\n",
        "\n",
        "        x4 = self.Maxpool(x3)\n",
        "        x4 = self.Conv4(x4)\n",
        "\n",
        "        x5 = self.Maxpool(x4)\n",
        "        x5 = self.Conv5(x5)\n",
        "\n",
        "        # decoding + concat path\n",
        "        d5 = self.Up5(x5)\n",
        "        d5 = torch.cat((x4, d5), dim=1)\n",
        "\n",
        "        d5 = self.Up_conv5(d5)\n",
        "\n",
        "        d4 = self.Up4(d5)\n",
        "        d4 = torch.cat((x3, d4), dim=1)\n",
        "        d4 = self.Up_conv4(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        d3 = torch.cat((x2, d3), dim=1)\n",
        "        d3 = self.Up_conv3(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        d2 = torch.cat((x1, d2), dim=1)\n",
        "        d2 = self.Up_conv2(d2)\n",
        "\n",
        "        # d1 = self.Conv_1x1(d2)\n",
        "        d1 = self.Conv_1x1(d2).squeeze(1)\n",
        "\n",
        "        return d1"
      ],
      "metadata": {
        "id": "36SZiDpcKTAN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "eOo8eW1sPnqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# UNet ONLY (your U_Net) + Drive logs + Weighted CE (Option C) + Improved training\n",
        "# FIXED:\n",
        "#   (1) Metrics: do NOT reward pred>0 when gt==0 (was inflating scores)\n",
        "#       - Return NaN for gt empty -> ignored in averages (recommended for slice-based)\n",
        "#   (2) Dice loss: exclude background class (c=0) so loss aligns with organ classes\n",
        "#   (3) CSV/log macro metrics computed with NaN-safe means\n",
        "# NOTE:\n",
        "#   - U_Net is assumed already implemented in your runtime (do NOT redefine it here)\n",
        "#   - RandomGenerator and Synapse_dataset assumed available too\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import argparse\n",
        "import datetime\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from medpy import metric as medpy_metric\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Wrapper: ensure logits shape is (B, C, H, W)\n",
        "# -------------------------\n",
        "class UNetLogitsWrapper(nn.Module):\n",
        "    def __init__(self, base_unet):\n",
        "        super().__init__()\n",
        "        self.m = base_unet\n",
        "\n",
        "    def forward(self, x):\n",
        "        # If your U_Net forward already returns logits (B,C,H,W), just return it:\n",
        "        out = self.m(x)\n",
        "        # Some UNet variants mistakenly squeeze channel; protect:\n",
        "        if out.dim() == 3:\n",
        "            # (B,H,W) -> cannot recover C, so raise\n",
        "            raise RuntimeError(\"U_Net output is (B,H,W). Please make it return logits (B,C,H,W).\")\n",
        "        return out\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Metrics (MedPy) - FIXED\n",
        "#   - If gt is empty for a class in a slice => return NaN (ignored in mean)\n",
        "#   - If gt exists but pred empty => dice=0, jac=0, hd95=NaN\n",
        "# -------------------------\n",
        "def calculate_metric_percase(pred, gt):\n",
        "    pred = pred.astype(np.uint8)\n",
        "    gt = gt.astype(np.uint8)\n",
        "    pred[pred > 0] = 1\n",
        "    gt[gt > 0] = 1\n",
        "\n",
        "    if gt.sum() == 0:\n",
        "        # class absent in GT for this slice: do not include in average\n",
        "        return np.nan, np.nan, np.nan\n",
        "\n",
        "    if pred.sum() == 0:\n",
        "        # missed the structure\n",
        "        return 0.0, 0.0, np.nan\n",
        "\n",
        "    dice = medpy_metric.binary.dc(pred, gt)\n",
        "    jac = medpy_metric.binary.jc(pred, gt)\n",
        "    hd95 = medpy_metric.binary.hd95(pred, gt)\n",
        "    return float(dice), float(jac), float(hd95)\n",
        "\n",
        "\n",
        "def multilabel_metric(pred_2d, gt_2d, num_classes):\n",
        "    metric_list = []\n",
        "    for i in range(1, num_classes):  # exclude background\n",
        "        metric_list.append(calculate_metric_percase(pred_2d == i, gt_2d == i))\n",
        "    return metric_list\n",
        "\n",
        "\n",
        "def init_running_metrics(num_classes: int):\n",
        "    return {\n",
        "        \"dice_sum\": {c: 0.0 for c in range(1, num_classes)},\n",
        "        \"jac_sum\":  {c: 0.0 for c in range(1, num_classes)},\n",
        "        \"hd95_sum\": {c: 0.0 for c in range(1, num_classes)},\n",
        "        \"count\":    {c: 0   for c in range(1, num_classes)},\n",
        "    }\n",
        "\n",
        "\n",
        "def update_running_metrics(running, pred_2d, gt_2d, num_classes: int):\n",
        "    mlist = multilabel_metric(pred_2d, gt_2d, num_classes)\n",
        "    for cls_idx, (dice, jac, hd95) in enumerate(mlist, start=1):\n",
        "        if not np.isnan(dice):\n",
        "            running[\"dice_sum\"][cls_idx] += float(dice)\n",
        "        if not np.isnan(jac):\n",
        "            running[\"jac_sum\"][cls_idx] += float(jac)\n",
        "        if not np.isnan(hd95):\n",
        "            running[\"hd95_sum\"][cls_idx] += float(hd95)\n",
        "        # count increments only if gt exists (we returned NaN when gt empty)\n",
        "        if not np.isnan(dice) or not np.isnan(jac) or not np.isnan(hd95):\n",
        "            running[\"count\"][cls_idx] += 1\n",
        "    return running\n",
        "\n",
        "\n",
        "def finalize_metrics(running, num_classes: int):\n",
        "    per_class = {}\n",
        "    dice_vals, jac_vals, hd95_vals = [], [], []\n",
        "\n",
        "    for c in range(1, num_classes):\n",
        "        cnt = running[\"count\"][c]\n",
        "        if cnt > 0:\n",
        "            d = running[\"dice_sum\"][c] / cnt\n",
        "            j = running[\"jac_sum\"][c] / cnt\n",
        "            h = running[\"hd95_sum\"][c] / cnt\n",
        "        else:\n",
        "            d, j, h = np.nan, np.nan, np.nan\n",
        "\n",
        "        per_class[c] = (float(d) if not np.isnan(d) else np.nan,\n",
        "                        float(j) if not np.isnan(j) else np.nan,\n",
        "                        float(h) if not np.isnan(h) else np.nan)\n",
        "\n",
        "        dice_vals.append(d)\n",
        "        jac_vals.append(j)\n",
        "        hd95_vals.append(h)\n",
        "\n",
        "    macro_dice = float(np.nanmean(dice_vals)) if len(dice_vals) else np.nan\n",
        "    macro_jac  = float(np.nanmean(jac_vals))  if len(jac_vals)  else np.nan\n",
        "    macro_hd95 = float(np.nanmean(hd95_vals)) if len(hd95_vals) else np.nan\n",
        "\n",
        "    return per_class, (macro_dice, macro_jac, macro_hd95)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Losses\n",
        "#   - FIX: exclude background in Dice loss\n",
        "# -------------------------\n",
        "class BinaryDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input, targets):\n",
        "        N = targets.size(0)\n",
        "        smooth = 1.0\n",
        "        input_flat = input.view(N, -1)\n",
        "        targets_flat = targets.view(N, -1)\n",
        "        inter = input_flat * targets_flat\n",
        "        dice_eff = (2 * inter.sum(1) + smooth) / (input_flat.sum(1) + targets_flat.sum(1) + smooth)\n",
        "        return 1 - dice_eff.sum() / N\n",
        "\n",
        "\n",
        "class MultiClassDiceLoss(nn.Module):\n",
        "    def __init__(self, class_weights=None, include_background=False):\n",
        "        super().__init__()\n",
        "        self.class_weights = class_weights\n",
        "        self.include_background = include_background\n",
        "        self.bdl = BinaryDiceLoss()\n",
        "\n",
        "    def forward(self, logits, target):\n",
        "        C = logits.shape[1]\n",
        "        target_oh = F.one_hot(target.long(), C).permute(0, 3, 1, 2).contiguous()\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        start_c = 0 if self.include_background else 1\n",
        "        losses = []\n",
        "        cls_ids = []\n",
        "        for c in range(start_c, C):\n",
        "            losses.append(self.bdl(probs[:, c], target_oh[:, c]))\n",
        "            cls_ids.append(c)\n",
        "\n",
        "        losses = torch.stack(losses, dim=0)\n",
        "\n",
        "        if self.class_weights is not None:\n",
        "            w = self.class_weights.to(losses.device)\n",
        "            if not self.include_background:\n",
        "                w = w[1:]  # drop background\n",
        "            w = w / (w.mean().clamp_min(1e-12))\n",
        "            return (losses * w).mean()\n",
        "\n",
        "        return losses.mean()\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Drive logging + CSV\n",
        "# -------------------------\n",
        "class TeeLogger:\n",
        "    def __init__(self, filename):\n",
        "        self.terminal = sys.stdout\n",
        "        self.log = open(filename, \"a\", encoding=\"utf8\")\n",
        "\n",
        "    def write(self, message):\n",
        "        self.terminal.write(message)\n",
        "        self.log.write(message)\n",
        "\n",
        "    def flush(self):\n",
        "        self.terminal.flush()\n",
        "        self.log.flush()\n",
        "        try:\n",
        "            os.fsync(self.log.fileno())\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "\n",
        "def setup_drive_logging(exp_dir):\n",
        "    logs_dir = os.path.join(exp_dir, \"logs\")\n",
        "    os.makedirs(logs_dir, exist_ok=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    log_path = os.path.join(logs_dir, f\"train_{ts}.log\")\n",
        "    sys.stdout = TeeLogger(log_path)\n",
        "    return log_path\n",
        "\n",
        "\n",
        "def append_csv(csv_path: str, header: str, line: str):\n",
        "    exists = os.path.isfile(csv_path)\n",
        "    with open(csv_path, \"a\", encoding=\"utf8\") as f:\n",
        "        if not exists:\n",
        "            f.write(header)\n",
        "        f.write(line)\n",
        "        f.flush()\n",
        "        try:\n",
        "            os.fsync(f.fileno())\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Option C: estimate weights\n",
        "# -------------------------\n",
        "def estimate_ce_weights_from_loader(train_loader, num_classes, device, max_batches=200, clamp_min=0.1, clamp_max=10.0):\n",
        "    counts = torch.zeros(num_classes, dtype=torch.float64)\n",
        "    for k, s in enumerate(train_loader):\n",
        "        if k >= max_batches:\n",
        "            break\n",
        "        y = s[\"label\"].view(-1)\n",
        "        counts += torch.bincount(y, minlength=num_classes).double()\n",
        "    freq = counts / counts.sum().clamp_min(1.0)\n",
        "    w = 1.0 / (freq + 1e-12)\n",
        "    w = w / w.mean().clamp_min(1e-12)\n",
        "    w = w.float()\n",
        "    w = torch.clamp(w, clamp_min, clamp_max).to(device)\n",
        "    return w, counts\n",
        "\n",
        "\n",
        "def estimate_dice_weights_from_ce_weights(ce_w):\n",
        "    w = ce_w.clone().detach().float()\n",
        "    # background weight not used when include_background=False, but keep stable anyway\n",
        "    w[0] = min(float(w[0]), 1.0)\n",
        "    w = w / w.mean().clamp_min(1e-12)\n",
        "    return w\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Args\n",
        "# -------------------------\n",
        "def get_argparser():\n",
        "    p = argparse.ArgumentParser()\n",
        "\n",
        "    p.add_argument(\"--versions_root\", type=str, default=\"/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\")\n",
        "    p.add_argument(\"--data_subdir\", type=str, default=\"Synapse\")\n",
        "    p.add_argument(\"--list_dir\", type=str, default=\"/root/lists_synapse\")\n",
        "    p.add_argument(\"--train_folder\", type=str, default=\"train_npz\")\n",
        "    p.add_argument(\"--test_folder\", type=str, default=\"test_vol_h5\")\n",
        "\n",
        "    p.add_argument(\"--num_classes\", type=int, default=9)\n",
        "    p.add_argument(\"--START_EPOCH\", type=int, default=0)\n",
        "    p.add_argument(\"--NB_EPOCH\", type=int, default=100)\n",
        "\n",
        "    p.add_argument(\"--LR\", type=float, default=3e-4)\n",
        "    p.add_argument(\"--weight_decay\", type=float, default=1e-4)\n",
        "\n",
        "    p.add_argument(\"--batch_size\", type=int, default=4)\n",
        "    p.add_argument(\"--img_size\", type=int, default=224)\n",
        "\n",
        "    p.add_argument(\"--RESUME\", type=bool, default=False)\n",
        "    p.add_argument(\"--random_seed\", type=int, default=1234)\n",
        "\n",
        "    p.add_argument(\"--metrics_every\", type=int, default=10)\n",
        "\n",
        "    p.add_argument(\"--gamma\", type=float, default=0.9)\n",
        "    p.add_argument(\"--lr_step\", type=int, default=10)\n",
        "    p.add_argument(\"--warmup_epochs\", type=int, default=5)\n",
        "\n",
        "    p.add_argument(\"--grad_clip\", type=float, default=1.0)\n",
        "\n",
        "    p.add_argument(\"--drive_root\", type=str, default=\"/content/drive/MyDrive/Synapse_experiments\")\n",
        "    p.add_argument(\"--exp_name\", type=str, default=\"Synapse_UNet_only\")\n",
        "\n",
        "    p.add_argument(\"--ce_weight_batches\", type=int, default=200)\n",
        "    p.add_argument(\"--ce_w_min\", type=float, default=0.1)\n",
        "    p.add_argument(\"--ce_w_max\", type=float, default=10.0)\n",
        "\n",
        "    p.add_argument(\"--save_best_on\", type=str, default=\"macro_dice\", choices=[\"macro_dice\", \"loss\"])\n",
        "\n",
        "    return p\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Main\n",
        "# -------------------------\n",
        "def main():\n",
        "    opts = get_argparser().parse_known_args()[0]\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "    exp_dir = os.path.join(opts.drive_root, opts.exp_name)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    ckpt_dir = os.path.join(exp_dir, \"checkpoints\")\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "    log_path = setup_drive_logging(exp_dir)\n",
        "    print(\"✅ Logging to:\", log_path)\n",
        "    print(\"✅ Exp dir:\", exp_dir)\n",
        "\n",
        "    csv_path = os.path.join(exp_dir, \"history_unet.csv\")\n",
        "    C = opts.num_classes\n",
        "    header_cols = [\n",
        "        \"epoch\", \"lr\", \"loss\", \"ce\", \"dice_loss\", \"macro_dice\", \"macro_jac\", \"macro_hd95\"\n",
        "    ]\n",
        "    for c in range(1, C):\n",
        "        header_cols += [f\"dice_c{c:02d}\", f\"jac_c{c:02d}\", f\"hd95_c{c:02d}\"]\n",
        "    header = \",\".join(header_cols) + \"\\n\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    torch.manual_seed(opts.random_seed)\n",
        "    np.random.seed(opts.random_seed)\n",
        "    random.seed(opts.random_seed)\n",
        "\n",
        "    tr_transform = RandomGenerator(output_size=[opts.img_size, opts.img_size])\n",
        "\n",
        "    train_dataset = Synapse_dataset(\n",
        "        versions_root=opts.versions_root,\n",
        "        split=\"train\",\n",
        "        transform=tr_transform,\n",
        "        list_dir=opts.list_dir,\n",
        "        data_subdir=opts.data_subdir,\n",
        "        train_folder=opts.train_folder,\n",
        "        test_folder=opts.test_folder,\n",
        "        verbose=True,\n",
        "    )\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=opts.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    # -------------------------\n",
        "    # Model: U_Net is assumed implemented already\n",
        "    #   Must return logits (B, C, H, W)\n",
        "    # -------------------------\n",
        "    base_unet = U_Net(img_ch=3, num_class=C)  # uses your existing implementation\n",
        "    model = UNetLogitsWrapper(base_unet).to(device)\n",
        "\n",
        "    unet_last_path = os.path.join(ckpt_dir, \"UNet_last.pth\")\n",
        "    unet_best_path = os.path.join(ckpt_dir, \"UNet_best.pth\")\n",
        "\n",
        "    if opts.RESUME and os.path.isfile(unet_last_path):\n",
        "        print(\"Loading UNet checkpoint:\", unet_last_path)\n",
        "        model.load_state_dict(torch.load(unet_last_path, map_location=device), strict=True)\n",
        "\n",
        "    ce_w, counts = estimate_ce_weights_from_loader(\n",
        "        train_loader, C, device,\n",
        "        max_batches=opts.ce_weight_batches,\n",
        "        clamp_min=opts.ce_w_min,\n",
        "        clamp_max=opts.ce_w_max,\n",
        "    )\n",
        "    print(\"Pixel counts:\", counts.cpu().numpy().astype(np.int64))\n",
        "    print(\"CE weights:\", ce_w.detach().cpu().numpy())\n",
        "\n",
        "    ce_loss = nn.CrossEntropyLoss(weight=ce_w, reduction=\"mean\")\n",
        "\n",
        "    dice_w = estimate_dice_weights_from_ce_weights(ce_w)\n",
        "    dice_loss = MultiClassDiceLoss(class_weights=dice_w, include_background=False)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=opts.LR, weight_decay=opts.weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=opts.lr_step, gamma=opts.gamma)\n",
        "\n",
        "    best_score = -1e9 if opts.save_best_on == \"macro_dice\" else 1e9\n",
        "\n",
        "    for epoch in range(opts.START_EPOCH, opts.NB_EPOCH):\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        if opts.warmup_epochs > 0 and epoch < opts.warmup_epochs:\n",
        "            warm_lr = opts.LR * float(epoch + 1) / float(opts.warmup_epochs)\n",
        "            for pg in optimizer.param_groups:\n",
        "                pg[\"lr\"] = warm_lr\n",
        "            lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(f\"Epoch {epoch}/{opts.NB_EPOCH-1} | lr={lr:.6g} | StepLR(gamma={opts.gamma}, step={opts.lr_step}) | warmup={opts.warmup_epochs}\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        model.train()\n",
        "        running = init_running_metrics(C)\n",
        "\n",
        "        loss_sum = 0.0\n",
        "        ce_sum = 0.0\n",
        "        dice_sum = 0.0\n",
        "        n_batches = 0\n",
        "\n",
        "        for i, samples in tqdm(enumerate(train_loader), total=len(train_loader), desc=\"TRAIN\"):\n",
        "            images = samples[\"image\"]\n",
        "            labels = samples[\"label\"]\n",
        "\n",
        "            if images.size(1) == 1:\n",
        "                images = images.repeat(1, 3, 1, 1)\n",
        "\n",
        "            imgs = images.to(device, dtype=torch.float32, non_blocking=True)\n",
        "            gts = labels.to(device, dtype=torch.long, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            logits = model(imgs)\n",
        "\n",
        "            loss_ce = ce_loss(logits, gts)\n",
        "            loss_d = dice_loss(logits, gts)\n",
        "            loss = loss_ce + loss_d\n",
        "\n",
        "            loss.backward()\n",
        "            if opts.grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), opts.grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_sum += float(loss.detach().cpu())\n",
        "            ce_sum += float(loss_ce.detach().cpu())\n",
        "            dice_sum += float(loss_d.detach().cpu())\n",
        "            n_batches += 1\n",
        "\n",
        "            if i % 20 == 0:\n",
        "                print(f\"[batch {i:04d}] loss={loss.item():.4f} | ce={loss_ce.item():.4f} | dice={loss_d.item():.4f}\")\n",
        "\n",
        "            if opts.metrics_every > 0 and (i % opts.metrics_every == 0):\n",
        "                with torch.no_grad():\n",
        "                    pred = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
        "                    pred_np = pred.detach().cpu().numpy()\n",
        "                    gt_np = gts.detach().cpu().numpy()\n",
        "                    for b in range(pred_np.shape[0]):\n",
        "                        running = update_running_metrics(running, pred_np[b], gt_np[b], C)\n",
        "\n",
        "        epoch_loss = loss_sum / max(1, n_batches)\n",
        "        epoch_ce = ce_sum / max(1, n_batches)\n",
        "        epoch_dice = dice_sum / max(1, n_batches)\n",
        "\n",
        "        per_class, macro = finalize_metrics(running, C)\n",
        "        macro_dice, macro_jac, macro_hd95 = macro\n",
        "\n",
        "        print(\"\\n--- Epoch Summary ---\")\n",
        "        print(f\"Loss={epoch_loss:.6f} | CE={epoch_ce:.6f} | DiceLoss={epoch_dice:.6f}\")\n",
        "        print(f\"[METRICS] Macro Dice={macro_dice:.4f} | Jaccard={macro_jac:.4f} | HD95={macro_hd95:.4f}\")\n",
        "        for c in range(1, C):\n",
        "            d, j, h = per_class[c]\n",
        "            print(f\"[METRICS] Class {c:02d}: Dice={d:.4f} | Jaccard={j:.4f} | HD95={h:.4f}\")\n",
        "\n",
        "        torch.save(model.state_dict(), unet_last_path)\n",
        "        print(\"✅ Saved UNet last checkpoint:\", unet_last_path)\n",
        "\n",
        "        def _fmt(x):\n",
        "            return \"\" if (x is None or (isinstance(x, float) and np.isnan(x))) else f\"{x}\"\n",
        "\n",
        "        row = [\n",
        "            str(epoch),\n",
        "            f\"{lr}\",\n",
        "            f\"{epoch_loss}\",\n",
        "            f\"{epoch_ce}\",\n",
        "            f\"{epoch_dice}\",\n",
        "            _fmt(macro_dice),\n",
        "            _fmt(macro_jac),\n",
        "            _fmt(macro_hd95),\n",
        "        ]\n",
        "        for c in range(1, C):\n",
        "            d, j, h = per_class[c]\n",
        "            row += [_fmt(d), _fmt(j), _fmt(h)]\n",
        "        line = \",\".join(row) + \"\\n\"\n",
        "        append_csv(csv_path, header, line)\n",
        "\n",
        "        try:\n",
        "            sys.stdout.flush()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        if opts.save_best_on == \"macro_dice\":\n",
        "            score = macro_dice\n",
        "            if not np.isnan(score) and score > best_score:\n",
        "                best_score = score\n",
        "                torch.save(model.state_dict(), unet_best_path)\n",
        "                print(f\"✅ Saved UNet best checkpoint (macro_dice={best_score:.4f}):\", unet_best_path)\n",
        "        else:\n",
        "            score = epoch_loss\n",
        "            if score < best_score:\n",
        "                best_score = score\n",
        "                torch.save(model.state_dict(), unet_best_path)\n",
        "                print(f\"✅ Saved UNet best checkpoint (loss={best_score:.6f}):\", unet_best_path)\n",
        "\n",
        "        if not (opts.warmup_epochs > 0 and epoch < opts.warmup_epochs):\n",
        "            scheduler.step()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Done.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kztVkawXM34j",
        "outputId": "f85f4512-d528-4354-98af-3c7cfc9c80b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|██████████| 553/553 [02:44<00:00,  3.36it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:42<00:00,  3.40it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:43<00:00,  3.38it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:44<00:00,  3.37it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:43<00:00,  3.38it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:44<00:00,  3.37it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:44<00:00,  3.36it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:43<00:00,  3.37it/s]\n",
            "TRAIN:  37%|███▋      | 207/553 [01:01<01:40,  3.44it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# debugging"
      ],
      "metadata": {
        "id": "sM7xVuVBfOZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# ALL-IN-ONE DEBUG CELL (Synapse)\n",
        "# - mounts Drive (optional)\n",
        "# - builds dataset + loader (train)\n",
        "# - builds UNet (your architecture) with logits wrapper\n",
        "# - runs 1 forward pass on 1 batch\n",
        "# - prints: shapes, GT/PRED unique labels, per-class pixel counts, CE/Dice loss on that batch\n",
        "# =========================\n",
        "\n",
        "import os, sys, random, datetime\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from medpy import metric as medpy_metric\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "\n",
        "# --------- CONFIG (edit if needed) ----------\n",
        "class CFG:\n",
        "    versions_root = \"/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\"\n",
        "    data_subdir   = \"Synapse\"\n",
        "    list_dir      = \"/root/lists_synapse\"\n",
        "    train_folder  = \"train_npz\"\n",
        "    test_folder   = \"test_vol_h5\"\n",
        "    split         = \"train\"     # \"train\" or \"test\"\n",
        "    img_size      = 224\n",
        "    batch_size    = 2\n",
        "    num_classes   = 9\n",
        "    num_workers   = 2\n",
        "    seed          = 1234\n",
        "    mount_drive   = False       # True if you want Drive mounted\n",
        "    drive_root    = \"/content/drive/MyDrive/Synapse_debug\"  # used only if mount_drive=True\n",
        "\n",
        "cfg = CFG()\n",
        "\n",
        "\n",
        "# --------- SEED ----------\n",
        "torch.manual_seed(cfg.seed)\n",
        "np.random.seed(cfg.seed)\n",
        "random.seed(cfg.seed)\n",
        "\n",
        "\n",
        "# --------- DEVICE ----------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "\n",
        "# --------- OPTIONAL DRIVE ----------\n",
        "if IN_COLAB and cfg.mount_drive:\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "    os.makedirs(cfg.drive_root, exist_ok=True)\n",
        "    print(\"Drive mounted. Debug root:\", cfg.drive_root)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Your UNet (as-is) + logits wrapper\n",
        "# =========================\n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(ch_in, ch_out, 3, 1, 1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch_out, ch_out, 3, 1, 1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class up_conv(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super().__init__()\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(ch_in, ch_out, 3, 1, 1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.up(x)\n",
        "\n",
        "class U_Net(nn.Module):\n",
        "    def __init__(self, img_ch=3, num_class=9):\n",
        "        super().__init__()\n",
        "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.Conv1 = conv_block(img_ch, 64)\n",
        "        self.Conv2 = conv_block(64, 128)\n",
        "        self.Conv3 = conv_block(128, 256)\n",
        "        self.Conv4 = conv_block(256, 512)\n",
        "        self.Conv5 = conv_block(512, 1024)\n",
        "\n",
        "        self.Up5 = up_conv(1024, 512)\n",
        "        self.Up_conv5 = conv_block(1024, 512)\n",
        "\n",
        "        self.Up4 = up_conv(512, 256)\n",
        "        self.Up_conv4 = conv_block(512, 256)\n",
        "\n",
        "        self.Up3 = up_conv(256, 128)\n",
        "        self.Up_conv3 = conv_block(256, 128)\n",
        "\n",
        "        self.Up2 = up_conv(128, 64)\n",
        "        self.Up_conv2 = conv_block(128, 64)\n",
        "\n",
        "        self.Conv_1x1 = nn.Conv2d(64, num_class, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.Conv1(x)\n",
        "\n",
        "        x2 = self.Maxpool(x1); x2 = self.Conv2(x2)\n",
        "        x3 = self.Maxpool(x2); x3 = self.Conv3(x3)\n",
        "        x4 = self.Maxpool(x3); x4 = self.Conv4(x4)\n",
        "        x5 = self.Maxpool(x4); x5 = self.Conv5(x5)\n",
        "\n",
        "        d5 = self.Up5(x5); d5 = torch.cat((x4, d5), dim=1); d5 = self.Up_conv5(d5)\n",
        "        d4 = self.Up4(d5); d4 = torch.cat((x3, d4), dim=1); d4 = self.Up_conv4(d4)\n",
        "        d3 = self.Up3(d4); d3 = torch.cat((x2, d3), dim=1); d3 = self.Up_conv3(d3)\n",
        "        d2 = self.Up2(d3); d2 = torch.cat((x1, d2), dim=1); d2 = self.Up_conv2(d2)\n",
        "\n",
        "        d1 = self.Conv_1x1(d2).squeeze(1)\n",
        "        return d1\n",
        "\n",
        "class UNetLogitsWrapper(nn.Module):\n",
        "    def __init__(self, base_unet: U_Net):\n",
        "        super().__init__()\n",
        "        self.m = base_unet\n",
        "    def forward(self, x):\n",
        "        x1 = self.m.Conv1(x)\n",
        "        x2 = self.m.Maxpool(x1); x2 = self.m.Conv2(x2)\n",
        "        x3 = self.m.Maxpool(x2); x3 = self.m.Conv3(x3)\n",
        "        x4 = self.m.Maxpool(x3); x4 = self.m.Conv4(x4)\n",
        "        x5 = self.m.Maxpool(x4); x5 = self.m.Conv5(x5)\n",
        "\n",
        "        d5 = self.m.Up5(x5); d5 = torch.cat((x4, d5), dim=1); d5 = self.m.Up_conv5(d5)\n",
        "        d4 = self.m.Up4(d5); d4 = torch.cat((x3, d4), dim=1); d4 = self.m.Up_conv4(d4)\n",
        "        d3 = self.m.Up3(d4); d3 = torch.cat((x2, d3), dim=1); d3 = self.m.Up_conv3(d3)\n",
        "        d2 = self.m.Up2(d3); d2 = torch.cat((x1, d2), dim=1); d2 = self.m.Up_conv2(d2)\n",
        "\n",
        "        return self.m.Conv_1x1(d2)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Dice loss (same as your training)\n",
        "# =========================\n",
        "class BinaryDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self, input, targets):\n",
        "        N = targets.size(0)\n",
        "        smooth = 1.0\n",
        "        input_flat = input.view(N, -1)\n",
        "        targets_flat = targets.view(N, -1)\n",
        "        intersection = input_flat * targets_flat\n",
        "        dice_eff = (2 * intersection.sum(1) + smooth) / (input_flat.sum(1) + targets_flat.sum(1) + smooth)\n",
        "        return 1 - dice_eff.sum() / N\n",
        "\n",
        "class MultiClassDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self, input, target):\n",
        "        nclass = input.shape[1]\n",
        "        target_oh = F.one_hot(target.long(), nclass).permute(0, 3, 1, 2).contiguous()\n",
        "        probs = F.softmax(input, dim=1)\n",
        "        bdl = BinaryDiceLoss()\n",
        "        total = 0.0\n",
        "        for c in range(nclass):\n",
        "            total += bdl(probs[:, c], target_oh[:, c])\n",
        "        return total / nclass\n",
        "\n",
        "\n",
        "# =========================\n",
        "# REQUIRE: your Synapse_dataset + RandomGenerator already exist\n",
        "# =========================\n",
        "assert \"Synapse_dataset\" in globals(), \"Synapse_dataset is not defined in this runtime.\"\n",
        "assert \"RandomGenerator\" in globals(), \"RandomGenerator is not defined in this runtime.\"\n",
        "\n",
        "tr = RandomGenerator(output_size=[cfg.img_size, cfg.img_size])\n",
        "ds = Synapse_dataset(\n",
        "    versions_root=cfg.versions_root,\n",
        "    split=cfg.split,\n",
        "    transform=tr,\n",
        "    list_dir=cfg.list_dir,\n",
        "    data_subdir=cfg.data_subdir,\n",
        "    train_folder=cfg.train_folder,\n",
        "    test_folder=cfg.test_folder,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "print(f\"Dataset split='{cfg.split}' size:\", len(ds))\n",
        "\n",
        "loader = DataLoader(\n",
        "    ds,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=cfg.num_workers,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Build model\n",
        "# =========================\n",
        "base = U_Net(img_ch=3, num_class=cfg.num_classes)\n",
        "model = UNetLogitsWrapper(base).to(device)\n",
        "model.eval()\n",
        "\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "dice_loss = MultiClassDiceLoss()\n",
        "\n",
        "# =========================\n",
        "# Take ONE batch and debug\n",
        "# =========================\n",
        "batch = next(iter(loader))\n",
        "images = batch[\"image\"]   # (B,1,H,W) likely\n",
        "labels = batch[\"label\"]   # (B,H,W)\n",
        "\n",
        "print(\"\\n--- RAW BATCH ---\")\n",
        "print(\"images:\", tuple(images.shape), images.dtype, \"min/max:\", float(images.min()), float(images.max()))\n",
        "print(\"labels:\", tuple(labels.shape), labels.dtype, \"min/max:\", int(labels.min()), int(labels.max()))\n",
        "print(\"GT unique labels:\", torch.unique(labels).tolist())\n",
        "\n",
        "gt_counts = torch.bincount(labels.view(-1), minlength=cfg.num_classes).cpu().tolist()\n",
        "print(\"GT counts per class:\", gt_counts)\n",
        "\n",
        "if images.size(1) == 1:\n",
        "    images = images.repeat(1, 3, 1, 1)\n",
        "\n",
        "imgs = images.to(device, dtype=torch.float32, non_blocking=True)\n",
        "gts  = labels.to(device, dtype=torch.long, non_blocking=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(imgs)                       # (B,C,H,W)\n",
        "    pred = torch.argmax(logits, dim=1).cpu()   # (B,H,W)\n",
        "\n",
        "print(\"\\n--- MODEL OUTPUT ---\")\n",
        "print(\"logits:\", tuple(logits.shape), logits.dtype)\n",
        "print(\"PRED unique labels:\", torch.unique(pred).tolist())\n",
        "\n",
        "pr_counts = torch.bincount(pred.view(-1), minlength=cfg.num_classes).cpu().tolist()\n",
        "print(\"PRED counts per class:\", pr_counts)\n",
        "\n",
        "# loss on this batch (just for sanity)\n",
        "with torch.no_grad():\n",
        "    l_ce = ce_loss(logits, gts).item()\n",
        "    l_d  = dice_loss(logits, gts).item()\n",
        "    l_tot = l_ce + l_d\n",
        "\n",
        "print(\"\\n--- LOSSES (one batch) ---\")\n",
        "print(f\"CE={l_ce:.6f} | DiceLoss={l_d:.6f} | Total={l_tot:.6f}\")\n",
        "\n",
        "# quick check: are we predicting mostly background?\n",
        "total_px = int(pred.numel())\n",
        "bg_pct = pr_counts[0] / max(1, total_px)\n",
        "print(f\"\\nBackground predicted %: {bg_pct*100:.2f}%\")\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "id": "Ib4twYwtP9QJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970229d7-80fd-4935-9400-c6bfd3c5bfd4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "VERSIONS ROOT: /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\n",
            "DATA ROOT    : /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse\n",
            "LIST DIR     : /root/lists_synapse\n",
            "LIST FILE    : /root/lists_synapse/train.txt\n",
            "TRAIN DIR    : /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/train_npz\n",
            "TEST  DIR    : /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/test_vol_h5\n",
            "Dataset split='train' size: 2211\n",
            "\n",
            "--- RAW BATCH ---\n",
            "images: (2, 1, 224, 224) torch.float32 min/max: -0.13874931633472443 1.2020628452301025\n",
            "labels: (2, 224, 224) torch.int64 min/max: 0 0\n",
            "GT unique labels: [0]\n",
            "GT counts per class: [100352, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "--- MODEL OUTPUT ---\n",
            "logits: (2, 9, 224, 224) torch.float32\n",
            "PRED unique labels: [3, 5, 6]\n",
            "PRED counts per class: [0, 0, 0, 19625, 0, 80725, 2, 0, 0]\n",
            "\n",
            "--- LOSSES (one batch) ---\n",
            "CE=2.209887 | DiceLoss=0.977868 | Total=3.187755\n",
            "\n",
            "Background predicted %: 0.00%\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FxJtatFEfSjD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}