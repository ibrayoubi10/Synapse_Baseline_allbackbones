{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data import"
      ],
      "metadata": {
        "id": "0uglUbtkIqkW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj1xOFaaIe-1",
        "outputId": "ec72fe76-765a-4714-af05-5a80b78e46f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (1.0.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/dogcdt/synapse?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 607M/607M [00:29<00:00, 21.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"dogcdt/synapse\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# losses and metrics"
      ],
      "metadata": {
        "id": "OOQD0qZHIu1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install medpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cEX-YQTJ11H",
        "outputId": "e0acb24b-6640-4d65-c20d-1dc59d4717f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medpy\n",
            "  Downloading medpy-0.5.2.tar.gz (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.3/156.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.12/dist-packages (from medpy) (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from medpy) (2.0.2)\n",
            "Collecting SimpleITK>=2.1 (from medpy)\n",
            "  Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.4 kB)\n",
            "Downloading simpleitk-2.5.3-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.5.2-py3-none-any.whl size=224710 sha256=89ce6602b3067aa0b0c56835c9982ae11f337cfa0dfbbd38e9ad0a6d933881bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/5a/f8/b3def53b9c2133d2f8698ea2173bb5df63bd8e761ce8e9aec9\n",
            "Successfully built medpy\n",
            "Installing collected packages: SimpleITK, medpy\n",
            "Successfully installed SimpleITK-2.5.3 medpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from medpy import metric\n",
        "from scipy.ndimage import zoom\n",
        "import torch.nn as nn\n",
        "import SimpleITK as sitk\n",
        "\n",
        "## metrics\n",
        "def calculate_metric_percase(pred, gt):\n",
        "    pred[pred > 0] = 1\n",
        "    gt[gt > 0] = 1\n",
        "    if pred.sum() > 0 and gt.sum()>0:\n",
        "        dice = metric.binary.dc(pred, gt)\n",
        "        hd95 = metric.binary.hd95(pred, gt)\n",
        "        jac = metric.binary.jc(pred, gt)\n",
        "        return dice, jac, hd95\n",
        "    elif pred.sum() > 0 and gt.sum()==0:\n",
        "        return 1, 1, 0\n",
        "    else:\n",
        "        return 0, 0, 0\n",
        "\n",
        "def multilabel_metric(pred, gt, num_classes):\n",
        "    gt = gt.squeeze(0)\n",
        "    metric_list = []\n",
        "    for i in range(1, num_classes):\n",
        "        metric_list.append(calculate_metric_percase(pred == i, gt == i))\n",
        "    return metric_list  # list, lenth=num_classes-1, 每个元素含有(x,y,z)\n",
        "\n",
        "# losses\n",
        "class BinaryDiceLoss(nn.Module):\n",
        "    def init(self):\n",
        "        super(BinaryDiceLoss, self).init()\n",
        "\n",
        "    def forward(self, input, targets):\n",
        "        # 获取每个批次的大小 N\n",
        "        N = targets.size()[0]\n",
        "        # 平滑变量\n",
        "        smooth = 1\n",
        "        # 将宽高 reshape 到同一纬度\n",
        "        input_flat = input.view(N, -1)\n",
        "        targets_flat = targets.view(N, -1)\n",
        "        # 计算交集\n",
        "        intersection = input_flat * targets_flat\n",
        "        N_dice_eff = (2 * intersection.sum(1) + smooth) / (input_flat.sum(1) + targets_flat.sum(1) + smooth)\n",
        "        # 计算一个批次中平均每张图的损失\n",
        "        loss = 1 - N_dice_eff.sum() / N\n",
        "        return loss\n",
        "\n",
        "\n",
        "class MultiClassDiceLoss(nn.Module):\n",
        "    def init(self, weight=None, ignore_index=None, **kwargs):\n",
        "        super(MultiClassDiceLoss, self).init()\n",
        "        self.weight = weight\n",
        "        self.ignore_index = ignore_index\n",
        "        self.kwargs = kwargs\n",
        "    def forward(self, input, target):\n",
        "        \"\"\"\n",
        "        input tesor of shape = (N, C, H, W)\n",
        "        target tensor of shape = (N, H, W)\n",
        "        \"\"\"\n",
        "        # 先将 target 进行 one-hot 处理，转换为 (N, C, H, W)\n",
        "        # target[target==255.] = 0.\n",
        "        nclass = input.shape[1]\n",
        "        target = F.one_hot(target.long(), nclass)\n",
        "        target = target.reshape(input.shape[0],input.shape[1],input.shape[2],-1)\n",
        "\n",
        "        assert input.shape == target.shape, \"predict & target shape do not match\"\n",
        "        binaryDiceLoss = BinaryDiceLoss()\n",
        "        total_loss = 0\n",
        "        # 归一化输出\n",
        "        logits = F.softmax(input, dim=1)\n",
        "        C = target.shape[1]\n",
        "        # 遍历 channel，得到每个类别的二分类 DiceLoss\n",
        "        for i in range(C):\n",
        "            dice_loss = binaryDiceLoss(logits[:, i], target[:, i])\n",
        "            total_loss += dice_loss\n",
        "            # 每个类别的平均 dice_loss\n",
        "        return total_loss / C"
      ],
      "metadata": {
        "id": "B8Y2K2IKIuQQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dataset manipulation"
      ],
      "metadata": {
        "id": "M7t9JusGKO_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage import zoom\n",
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Augmentations\n",
        "# -------------------------\n",
        "def random_rot_flip(image, label):\n",
        "    k = np.random.randint(0, 4)\n",
        "    image = np.rot90(image, k)\n",
        "    label = np.rot90(label, k)\n",
        "    axis = np.random.randint(0, 2)\n",
        "    image = np.flip(image, axis=axis).copy()\n",
        "    label = np.flip(label, axis=axis).copy()\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def random_rotate(image, label):\n",
        "    angle = np.random.randint(-20, 20)\n",
        "    image = ndimage.rotate(image, angle, order=0, reshape=False)\n",
        "    label = ndimage.rotate(label, angle, order=0, reshape=False)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "class RandomGenerator(object):\n",
        "    def __init__(self, output_size):\n",
        "        self.output_size = output_size  # (H, W)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample[\"image\"], sample[\"label\"]\n",
        "\n",
        "        if random.random() > 0.5:\n",
        "            image, label = random_rot_flip(image, label)\n",
        "        elif random.random() > 0.5:\n",
        "            image, label = random_rotate(image, label)\n",
        "\n",
        "        x, y = image.shape\n",
        "        if (x != self.output_size[0]) or (y != self.output_size[1]):\n",
        "            image = zoom(image, (self.output_size[0] / x, self.output_size[1] / y), order=3)\n",
        "            label = zoom(label, (self.output_size[0] / x, self.output_size[1] / y), order=0)\n",
        "\n",
        "        image = torch.from_numpy(image.astype(np.float32)).unsqueeze(0)  # (1, H, W)\n",
        "        label = torch.from_numpy(label.astype(np.int64))                 # (H, W)\n",
        "        return {\"image\": image, \"label\": label}\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Dataset\n",
        "# -------------------------\n",
        "class Synapse_dataset(Dataset):\n",
        "    \"\"\"\n",
        "    Your structure:\n",
        "\n",
        "    /root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1/Synapse/\n",
        "        train_npz/\n",
        "        test_vol_h5/   (or whatever your test folder is)\n",
        "    /root/lists_synapse/\n",
        "        train.txt\n",
        "        test_vol.txt\n",
        "\n",
        "    Train slices: <name>.npz with keys (image, label)\n",
        "    Test volumes: <name>.npy.h5 OR <name>.h5 OR <name>.n5 with datasets (image, label)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        versions_root=\"/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\",\n",
        "        split=\"train\",\n",
        "        transform=None,\n",
        "        list_dir=\"/root/lists_synapse\",\n",
        "        data_subdir=\"Synapse\",          # <-- IMPORTANT: your extra folder level\n",
        "        train_folder=\"train_npz\",\n",
        "        test_folder=\"test_vol_h5\",\n",
        "        train_list=\"train.txt\",\n",
        "        test_list=\"test_vol.txt\",\n",
        "        verbose=True,\n",
        "    ):\n",
        "        self.transform = transform\n",
        "        self.split = split.lower().strip()\n",
        "\n",
        "        versions_root = Path(versions_root).expanduser().resolve()\n",
        "        self.data_root = (versions_root / data_subdir).resolve()  # <-- /.../versions/1/Synapse\n",
        "\n",
        "        list_dir = Path(list_dir).expanduser()\n",
        "        self.list_dir = list_dir.resolve() if list_dir.is_absolute() else (self.data_root / list_dir).resolve()\n",
        "\n",
        "        self.train_dir = (self.data_root / train_folder).resolve()\n",
        "        self.test_dir = (self.data_root / test_folder).resolve()\n",
        "\n",
        "        list_file = self.list_dir / (train_list if self.split == \"train\" else test_list)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"VERSIONS ROOT:\", versions_root)\n",
        "            print(\"DATA ROOT    :\", self.data_root)\n",
        "            print(\"LIST DIR     :\", self.list_dir)\n",
        "            print(\"LIST FILE    :\", list_file)\n",
        "            print(\"TRAIN DIR    :\", self.train_dir)\n",
        "            print(\"TEST  DIR    :\", self.test_dir)\n",
        "\n",
        "        if not list_file.is_file():\n",
        "            raise FileNotFoundError(f\"Missing list file: {list_file}\")\n",
        "\n",
        "        self.sample_list = list_file.read_text().splitlines()\n",
        "\n",
        "        if self.split == \"train\" and not self.train_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Missing folder: {self.train_dir}\")\n",
        "        if self.split != \"train\" and not self.test_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Missing folder: {self.test_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_list)\n",
        "\n",
        "    def _resolve_train_path(self, name: str) -> Path:\n",
        "        return self.train_dir / f\"{name}.npz\"\n",
        "\n",
        "    def _resolve_test_path(self, name: str) -> Path:\n",
        "        candidates = [\n",
        "            self.test_dir / f\"{name}.npy.h5\",\n",
        "            self.test_dir / f\"{name}.h5\",\n",
        "            self.test_dir / f\"{name}.n5\",\n",
        "        ]\n",
        "        for p in candidates:\n",
        "            if p.is_file():\n",
        "                return p\n",
        "        return candidates[0]\n",
        "\n",
        "    def show_paths(self, max_items=20):\n",
        "        n = min(len(self.sample_list), max_items)\n",
        "        print(f\"Showing {n}/{len(self.sample_list)} paths for split='{self.split}'\")\n",
        "        for i in range(n):\n",
        "            name = self.sample_list[i].strip()\n",
        "            p = self._resolve_train_path(name) if self.split == \"train\" else self._resolve_test_path(name)\n",
        "            print(p, \"| exists =\", p.exists())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.sample_list[idx].strip()\n",
        "\n",
        "        if self.split == \"train\":\n",
        "            data_path = self._resolve_train_path(name)\n",
        "            if not data_path.is_file():\n",
        "                raise FileNotFoundError(f\"Missing train npz: {data_path}\")\n",
        "\n",
        "            data = np.load(str(data_path))\n",
        "            image, label = data[\"image\"], data[\"label\"]\n",
        "\n",
        "        else:\n",
        "            h5_path = self._resolve_test_path(name)\n",
        "            if not h5_path.is_file():\n",
        "                raise FileNotFoundError(\n",
        "                    \"Missing test volume. Tried: \"\n",
        "                    f\"{self.test_dir / (name + '.npy.h5')}, \"\n",
        "                    f\"{self.test_dir / (name + '.h5')}, \"\n",
        "                    f\"{self.test_dir / (name + '.n5')}\"\n",
        "                )\n",
        "\n",
        "            with h5py.File(str(h5_path), \"r\") as data:\n",
        "                image, label = data[\"image\"][:], data[\"label\"][:]\n",
        "\n",
        "        sample = {\"image\": image, \"label\": label}\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        sample[\"case_name\"] = name\n",
        "        return sample\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Quick local test\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    versions_root = \"/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\"\n",
        "    list_dir = \"/root/lists_synapse\"\n",
        "\n",
        "    ds_train = Synapse_dataset(versions_root=versions_root, split=\"train\", transform=None, list_dir=list_dir)\n",
        "    ds_train.show_paths(max_items=30)\n",
        "\n",
        "    ds_test = Synapse_dataset(versions_root=versions_root, split=\"test\", transform=None, list_dir=list_dir)\n",
        "    ds_test.show_paths(max_items=10)"
      ],
      "metadata": {
        "id": "fqHdNPp2JrIw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "https://github.com/Minerva-J/Pytorch-Segmentation-multi-models/blob/master/models/AttentionUnet/AttUnet.py\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(conv_block, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up_conv(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(up_conv, self).__init__()\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up(x)\n",
        "        return x\n",
        "\n",
        "class Attention_block(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super(Attention_block, self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "\n",
        "        return x * psi\n",
        "\n",
        "\n",
        "class U_Net(nn.Module):\n",
        "    def __init__(self, img_ch=3, num_class=9):\n",
        "        super(U_Net, self).__init__()\n",
        "\n",
        "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.Conv1 = conv_block(ch_in=img_ch, ch_out=64)\n",
        "        self.Conv2 = conv_block(ch_in=64, ch_out=128)\n",
        "        self.Conv3 = conv_block(ch_in=128, ch_out=256)\n",
        "        self.Conv4 = conv_block(ch_in=256, ch_out=512)\n",
        "        self.Conv5 = conv_block(ch_in=512, ch_out=1024)\n",
        "\n",
        "        self.Up5 = up_conv(ch_in=1024, ch_out=512)\n",
        "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
        "\n",
        "        self.Up4 = up_conv(ch_in=512, ch_out=256)\n",
        "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
        "\n",
        "        self.Up3 = up_conv(ch_in=256, ch_out=128)\n",
        "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
        "\n",
        "        self.Up2 = up_conv(ch_in=128, ch_out=64)\n",
        "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
        "\n",
        "        self.Conv_1x1 = nn.Conv2d(64, num_class, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoding path\n",
        "        x1 = self.Conv1(x)\n",
        "\n",
        "        x2 = self.Maxpool(x1)\n",
        "        x2 = self.Conv2(x2)\n",
        "\n",
        "        x3 = self.Maxpool(x2)\n",
        "        x3 = self.Conv3(x3)\n",
        "\n",
        "        x4 = self.Maxpool(x3)\n",
        "        x4 = self.Conv4(x4)\n",
        "\n",
        "        x5 = self.Maxpool(x4)\n",
        "        x5 = self.Conv5(x5)\n",
        "\n",
        "        # decoding + concat path\n",
        "        d5 = self.Up5(x5)\n",
        "        d5 = torch.cat((x4, d5), dim=1)\n",
        "\n",
        "        d5 = self.Up_conv5(d5)\n",
        "\n",
        "        d4 = self.Up4(d5)\n",
        "        d4 = torch.cat((x3, d4), dim=1)\n",
        "        d4 = self.Up_conv4(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        d3 = torch.cat((x2, d3), dim=1)\n",
        "        d3 = self.Up_conv3(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        d2 = torch.cat((x1, d2), dim=1)\n",
        "        d2 = self.Up_conv2(d2)\n",
        "\n",
        "        # d1 = self.Conv_1x1(d2)\n",
        "        d1 = self.Conv_1x1(d2).squeeze(1)\n",
        "\n",
        "        return d1"
      ],
      "metadata": {
        "id": "36SZiDpcKTAN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "eOo8eW1sPnqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import argparse\n",
        "import datetime\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from medpy import metric as medpy_metric\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#                 Metrics (MedPy)\n",
        "# ============================================================\n",
        "\n",
        "def calculate_metric_percase(pred, gt):\n",
        "    pred = pred.astype(np.uint8)\n",
        "    gt = gt.astype(np.uint8)\n",
        "    pred[pred > 0] = 1\n",
        "    gt[gt > 0] = 1\n",
        "\n",
        "    if gt.sum() == 0:\n",
        "        return np.nan, np.nan, np.nan\n",
        "\n",
        "    if pred.sum() == 0:\n",
        "        return 0.0, 0.0, np.nan\n",
        "\n",
        "    dice = medpy_metric.binary.dc(pred, gt)\n",
        "    jac = medpy_metric.binary.jc(pred, gt)\n",
        "    hd95 = medpy_metric.binary.hd95(pred, gt)\n",
        "    return float(dice), float(jac), float(hd95)\n",
        "\n",
        "\n",
        "def multilabel_metric(pred_2d, gt_2d, num_classes):\n",
        "    metric_list = []\n",
        "    for i in range(1, num_classes):\n",
        "        metric_list.append(calculate_metric_percase(pred_2d == i, gt_2d == i))\n",
        "    return metric_list\n",
        "\n",
        "\n",
        "def init_running_metrics(num_classes: int):\n",
        "    return {\n",
        "        \"dice_sum\": {c: 0.0 for c in range(1, num_classes)},\n",
        "        \"jac_sum\":  {c: 0.0 for c in range(1, num_classes)},\n",
        "        \"hd95_sum\": {c: 0.0 for c in range(1, num_classes)},\n",
        "        \"count\":    {c: 0   for c in range(1, num_classes)},\n",
        "    }\n",
        "\n",
        "\n",
        "def update_running_metrics(running, pred_2d, gt_2d, num_classes: int):\n",
        "    mlist = multilabel_metric(pred_2d, gt_2d, num_classes)\n",
        "    for cls_idx, (dice, jac, hd95) in enumerate(mlist, start=1):\n",
        "        if not np.isnan(dice):\n",
        "            running[\"dice_sum\"][cls_idx] += float(dice)\n",
        "        if not np.isnan(jac):\n",
        "            running[\"jac_sum\"][cls_idx] += float(jac)\n",
        "        if not np.isnan(hd95):\n",
        "            running[\"hd95_sum\"][cls_idx] += float(hd95)\n",
        "        if (not np.isnan(dice)) or (not np.isnan(jac)) or (not np.isnan(hd95)):\n",
        "            running[\"count\"][cls_idx] += 1\n",
        "    return running\n",
        "\n",
        "\n",
        "def finalize_metrics(running, num_classes: int):\n",
        "    per_class = {}\n",
        "    dice_vals, jac_vals, hd95_vals = [], [], []\n",
        "\n",
        "    for c in range(1, num_classes):\n",
        "        cnt = running[\"count\"][c]\n",
        "        if cnt > 0:\n",
        "            d = running[\"dice_sum\"][c] / cnt\n",
        "            j = running[\"jac_sum\"][c] / cnt\n",
        "            h = running[\"hd95_sum\"][c] / cnt\n",
        "        else:\n",
        "            d, j, h = np.nan, np.nan, np.nan\n",
        "\n",
        "        per_class[c] = (float(d) if not np.isnan(d) else np.nan,\n",
        "                        float(j) if not np.isnan(j) else np.nan,\n",
        "                        float(h) if not np.isnan(h) else np.nan)\n",
        "\n",
        "        dice_vals.append(d)\n",
        "        jac_vals.append(j)\n",
        "        hd95_vals.append(h)\n",
        "\n",
        "    macro_dice = float(np.nanmean(dice_vals)) if len(dice_vals) else np.nan\n",
        "    macro_jac  = float(np.nanmean(jac_vals))  if len(jac_vals)  else np.nan\n",
        "    macro_hd95 = float(np.nanmean(hd95_vals)) if len(hd95_vals) else np.nan\n",
        "\n",
        "    return per_class, (macro_dice, macro_jac, macro_hd95)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#                 Losses (Dice excludes background)\n",
        "# ============================================================\n",
        "\n",
        "class BinaryDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input, targets):\n",
        "        N = targets.size(0)\n",
        "        smooth = 1.0\n",
        "        input_flat = input.view(N, -1)\n",
        "        targets_flat = targets.view(N, -1)\n",
        "        inter = input_flat * targets_flat\n",
        "        dice_eff = (2 * inter.sum(1) + smooth) / (input_flat.sum(1) + targets_flat.sum(1) + smooth)\n",
        "        return 1 - dice_eff.sum() / N\n",
        "\n",
        "\n",
        "class MultiClassDiceLoss(nn.Module):\n",
        "    def __init__(self, class_weights=None, include_background=False):\n",
        "        super().__init__()\n",
        "        self.class_weights = class_weights\n",
        "        self.include_background = include_background\n",
        "        self.bdl = BinaryDiceLoss()\n",
        "\n",
        "    def forward(self, logits, target):\n",
        "        C = logits.shape[1]\n",
        "        target_oh = F.one_hot(target.long(), C).permute(0, 3, 1, 2).contiguous()\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        start_c = 0 if self.include_background else 1\n",
        "        losses = []\n",
        "        for c in range(start_c, C):\n",
        "            losses.append(self.bdl(probs[:, c], target_oh[:, c]))\n",
        "\n",
        "        losses = torch.stack(losses, dim=0)\n",
        "\n",
        "        if self.class_weights is not None:\n",
        "            w = self.class_weights.to(losses.device)\n",
        "            if not self.include_background:\n",
        "                w = w[1:]\n",
        "            w = w / (w.mean().clamp_min(1e-12))\n",
        "            return (losses * w).mean()\n",
        "\n",
        "        return losses.mean()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#                 Drive logging + CSV\n",
        "# ============================================================\n",
        "\n",
        "class TeeLogger:\n",
        "    def __init__(self, filename):\n",
        "        self.terminal = sys.stdout\n",
        "        self.log = open(filename, \"a\", encoding=\"utf8\")\n",
        "\n",
        "    def write(self, message):\n",
        "        self.terminal.write(message)\n",
        "        self.log.write(message)\n",
        "\n",
        "    def flush(self):\n",
        "        self.terminal.flush()\n",
        "        self.log.flush()\n",
        "        try:\n",
        "            os.fsync(self.log.fileno())\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "\n",
        "def setup_drive_logging(exp_dir):\n",
        "    logs_dir = os.path.join(exp_dir, \"logs\")\n",
        "    os.makedirs(logs_dir, exist_ok=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    log_path = os.path.join(logs_dir, f\"train_{ts}.log\")\n",
        "    sys.stdout = TeeLogger(log_path)\n",
        "    return log_path\n",
        "\n",
        "\n",
        "def append_csv(csv_path: str, header: str, line: str):\n",
        "    exists = os.path.isfile(csv_path)\n",
        "    with open(csv_path, \"a\", encoding=\"utf8\") as f:\n",
        "        if not exists:\n",
        "            f.write(header)\n",
        "        f.write(line)\n",
        "        f.flush()\n",
        "        try:\n",
        "            os.fsync(f.fileno())\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#                 Option C: estimate weights\n",
        "# ============================================================\n",
        "\n",
        "def estimate_ce_weights_from_loader(train_loader, num_classes, device,\n",
        "                                   max_batches=200, clamp_min=0.1, clamp_max=10.0):\n",
        "    counts = torch.zeros(num_classes, dtype=torch.float64)\n",
        "    for k, s in enumerate(train_loader):\n",
        "        if k >= max_batches:\n",
        "            break\n",
        "        y = s[\"label\"].view(-1)\n",
        "        counts += torch.bincount(y, minlength=num_classes).double()\n",
        "    freq = counts / counts.sum().clamp_min(1.0)\n",
        "    w = 1.0 / (freq + 1e-12)\n",
        "    w = w / w.mean().clamp_min(1e-12)\n",
        "    w = w.float()\n",
        "    w = torch.clamp(w, clamp_min, clamp_max).to(device)\n",
        "    return w, counts\n",
        "\n",
        "\n",
        "def estimate_dice_weights_from_ce_weights(ce_w):\n",
        "    w = ce_w.clone().detach().float()\n",
        "    w[0] = min(float(w[0]), 1.0)\n",
        "    w = w / w.mean().clamp_min(1e-12)\n",
        "    return w\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#                 Test wrapper: volume -> 2D slices\n",
        "# ============================================================\n",
        "\n",
        "class TestVol2DSliceDataset(Dataset):\n",
        "    def __init__(self, base_dataset):\n",
        "        self.base = base_dataset\n",
        "        self.index = []\n",
        "\n",
        "        for case_id in range(len(self.base)):\n",
        "            s = self.base[case_id]\n",
        "            img = s[\"image\"]\n",
        "            if isinstance(img, np.ndarray):\n",
        "                img = torch.from_numpy(img)\n",
        "            if img.dim() == 4:\n",
        "                D = img.shape[1]\n",
        "            elif img.dim() == 3:\n",
        "                D = img.shape[0]\n",
        "            else:\n",
        "                D = 1\n",
        "\n",
        "            for z in range(D):\n",
        "                self.index.append((case_id, z))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        case_id, z = self.index[idx]\n",
        "        s = self.base[case_id]\n",
        "\n",
        "        img = s[\"image\"]\n",
        "        lab = s[\"label\"]\n",
        "\n",
        "        if isinstance(img, np.ndarray):\n",
        "            img = torch.from_numpy(img)\n",
        "        if isinstance(lab, np.ndarray):\n",
        "            lab = torch.from_numpy(lab)\n",
        "\n",
        "        if img.dim() == 4:\n",
        "            img2d = img[0, z]\n",
        "        elif img.dim() == 3:\n",
        "            img2d = img[z]\n",
        "        elif img.dim() == 2:\n",
        "            img2d = img\n",
        "        else:\n",
        "            raise RuntimeError(f\"Unsupported image dim: {img.dim()}\")\n",
        "\n",
        "        if lab.dim() == 4:\n",
        "            lab2d = lab[0, z]\n",
        "        elif lab.dim() == 3:\n",
        "            lab2d = lab[z]\n",
        "        elif lab.dim() == 2:\n",
        "            lab2d = lab\n",
        "        else:\n",
        "            raise RuntimeError(f\"Unsupported label dim: {lab.dim()}\")\n",
        "\n",
        "        img2d = img2d.unsqueeze(0).float()\n",
        "        lab2d = lab2d.long()\n",
        "\n",
        "        return {\"image\": img2d, \"label\": lab2d}\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#                 2D prep\n",
        "# ============================================================\n",
        "\n",
        "def _prep_2d_batch(images, labels, img_size, device):\n",
        "    if images.size(1) == 1:\n",
        "        images = images.repeat(1, 3, 1, 1)\n",
        "\n",
        "    if images.shape[-2] != img_size or images.shape[-1] != img_size:\n",
        "        images = F.interpolate(images, size=(img_size, img_size), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "    if labels.shape[-2] != img_size or labels.shape[-1] != img_size:\n",
        "        labels = labels.unsqueeze(1).float()\n",
        "        labels = F.interpolate(labels, size=(img_size, img_size), mode=\"nearest\")\n",
        "        labels = labels.squeeze(1).long()\n",
        "\n",
        "    imgs = images.to(device, dtype=torch.float32, non_blocking=True)\n",
        "    gts = labels.to(device, dtype=torch.long, non_blocking=True)\n",
        "    return imgs, gts\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#                 Attention U-Net\n",
        "# ============================================================\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class up_conv(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super().__init__()\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False),\n",
        "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.up(x)\n",
        "\n",
        "\n",
        "class Attention_block(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super().__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "        return x * psi\n",
        "\n",
        "\n",
        "class AttU_Net(nn.Module):\n",
        "    def __init__(self, img_ch=3, num_class=9):\n",
        "        super().__init__()\n",
        "\n",
        "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.Conv1 = conv_block(ch_in=img_ch, ch_out=64)\n",
        "        self.Conv2 = conv_block(ch_in=64, ch_out=128)\n",
        "        self.Conv3 = conv_block(ch_in=128, ch_out=256)\n",
        "        self.Conv4 = conv_block(ch_in=256, ch_out=512)\n",
        "        self.Conv5 = conv_block(ch_in=512, ch_out=1024)\n",
        "\n",
        "        self.Up5 = up_conv(ch_in=1024, ch_out=512)\n",
        "        self.Att5 = Attention_block(F_g=512, F_l=512, F_int=256)\n",
        "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
        "\n",
        "        self.Up4 = up_conv(ch_in=512, ch_out=256)\n",
        "        self.Att4 = Attention_block(F_g=256, F_l=256, F_int=128)\n",
        "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
        "\n",
        "        self.Up3 = up_conv(ch_in=256, ch_out=128)\n",
        "        self.Att3 = Attention_block(F_g=128, F_l=128, F_int=64)\n",
        "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
        "\n",
        "        self.Up2 = up_conv(ch_in=128, ch_out=64)\n",
        "        self.Att2 = Attention_block(F_g=64, F_l=64, F_int=32)\n",
        "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
        "\n",
        "        self.Conv_1x1 = nn.Conv2d(64, num_class, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.Conv1(x)\n",
        "\n",
        "        x2 = self.Maxpool(x1)\n",
        "        x2 = self.Conv2(x2)\n",
        "\n",
        "        x3 = self.Maxpool(x2)\n",
        "        x3 = self.Conv3(x3)\n",
        "\n",
        "        x4 = self.Maxpool(x3)\n",
        "        x4 = self.Conv4(x4)\n",
        "\n",
        "        x5 = self.Maxpool(x4)\n",
        "        x5 = self.Conv5(x5)\n",
        "\n",
        "        d5 = self.Up5(x5)\n",
        "        x4_att = self.Att5(g=d5, x=x4)\n",
        "        d5 = torch.cat((x4_att, d5), dim=1)\n",
        "        d5 = self.Up_conv5(d5)\n",
        "\n",
        "        d4 = self.Up4(d5)\n",
        "        x3_att = self.Att4(g=d4, x=x3)\n",
        "        d4 = torch.cat((x3_att, d4), dim=1)\n",
        "        d4 = self.Up_conv4(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        x2_att = self.Att3(g=d3, x=x2)\n",
        "        d3 = torch.cat((x2_att, d3), dim=1)\n",
        "        d3 = self.Up_conv3(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        x1_att = self.Att2(g=d2, x=x1)\n",
        "        d2 = torch.cat((x1_att, d2), dim=1)\n",
        "        d2 = self.Up_conv2(d2)\n",
        "\n",
        "        logits = self.Conv_1x1(d2)  # (B,C,H,W)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#                 TEST eval (strict 2D) + loss\n",
        "# ============================================================\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_on_test_2d(model, test_loader, num_classes, img_size, device, ce_loss, dice_loss):\n",
        "    model.eval()\n",
        "    running = init_running_metrics(num_classes)\n",
        "\n",
        "    loss_sum = 0.0\n",
        "    ce_sum = 0.0\n",
        "    dice_sum = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    for samples in tqdm(test_loader, total=len(test_loader), desc=\"TEST_2D\"):\n",
        "        images = samples[\"image\"]\n",
        "        labels = samples[\"label\"]\n",
        "\n",
        "        imgs, gts = _prep_2d_batch(images, labels, img_size, device)\n",
        "\n",
        "        logits = model(imgs)\n",
        "        loss_ce = ce_loss(logits, gts)\n",
        "        loss_d = dice_loss(logits, gts)\n",
        "        loss = loss_ce + loss_d\n",
        "\n",
        "        loss_sum += float(loss.detach().cpu())\n",
        "        ce_sum += float(loss_ce.detach().cpu())\n",
        "        dice_sum += float(loss_d.detach().cpu())\n",
        "        n_batches += 1\n",
        "\n",
        "        pred = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
        "        pred_np = pred.detach().cpu().numpy()\n",
        "        gt_np = gts.detach().cpu().numpy()\n",
        "\n",
        "        for b in range(pred_np.shape[0]):\n",
        "            running = update_running_metrics(running, pred_np[b], gt_np[b], num_classes)\n",
        "\n",
        "    per_class, macro = finalize_metrics(running, num_classes)\n",
        "    test_loss = loss_sum / max(1, n_batches)\n",
        "    test_ce = ce_sum / max(1, n_batches)\n",
        "    test_dice_l = dice_sum / max(1, n_batches)\n",
        "\n",
        "    return per_class, macro, (test_loss, test_ce, test_dice_l)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#                 Args\n",
        "# ============================================================\n",
        "\n",
        "def get_argparser():\n",
        "    p = argparse.ArgumentParser()\n",
        "\n",
        "    p.add_argument(\"--versions_root\", type=str, default=\"/root/.cache/kagglehub/datasets/dogcdt/synapse/versions/1\")\n",
        "    p.add_argument(\"--data_subdir\", type=str, default=\"Synapse\")\n",
        "    p.add_argument(\"--list_dir\", type=str, default=\"/root/lists_synapse\")\n",
        "    p.add_argument(\"--train_folder\", type=str, default=\"train_npz\")\n",
        "    p.add_argument(\"--test_folder\", type=str, default=\"test_vol_h5\")\n",
        "\n",
        "    p.add_argument(\"--num_classes\", type=int, default=9)\n",
        "    p.add_argument(\"--START_EPOCH\", type=int, default=0)\n",
        "    p.add_argument(\"--NB_EPOCH\", type=int, default=50)\n",
        "\n",
        "    p.add_argument(\"--LR\", type=float, default=1e-4)\n",
        "    p.add_argument(\"--weight_decay\", type=float, default=1e-4)\n",
        "\n",
        "    p.add_argument(\"--batch_size\", type=int, default=4)\n",
        "    p.add_argument(\"--test_batch_size\", type=int, default=8)\n",
        "    p.add_argument(\"--img_size\", type=int, default=224)\n",
        "\n",
        "    p.add_argument(\"--RESUME\", type=bool, default=False)\n",
        "    p.add_argument(\"--random_seed\", type=int, default=1234)\n",
        "\n",
        "    p.add_argument(\"--metrics_every\", type=int, default=10)\n",
        "    p.add_argument(\"--grad_clip\", type=float, default=1.0)\n",
        "\n",
        "    p.add_argument(\"--drive_root\", type=str, default=\"/content/drive/MyDrive/Synapse_experiments\")\n",
        "    p.add_argument(\"--exp_name\", type=str, default=\"Synapse_AttUNet_only\")\n",
        "\n",
        "    p.add_argument(\"--ce_weight_batches\", type=int, default=200)\n",
        "    p.add_argument(\"--ce_w_min\", type=float, default=0.1)\n",
        "    p.add_argument(\"--ce_w_max\", type=float, default=10.0)\n",
        "\n",
        "    p.add_argument(\"--save_best_on\", type=str, default=\"macro_dice\", choices=[\"macro_dice\", \"loss\"])\n",
        "\n",
        "    return p\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#                 Main\n",
        "# ============================================================\n",
        "\n",
        "def main():\n",
        "    opts = get_argparser().parse_known_args()[0]\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "    exp_dir = os.path.join(opts.drive_root, opts.exp_name)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    ckpt_dir = os.path.join(exp_dir, \"checkpoints\")\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "    log_path = setup_drive_logging(exp_dir)\n",
        "    print(\"✅ Logging to:\", log_path)\n",
        "    print(\"✅ Exp dir:\", exp_dir)\n",
        "\n",
        "    csv_path = os.path.join(exp_dir, \"history_attunet.csv\")\n",
        "    C = opts.num_classes\n",
        "\n",
        "    header_cols = [\n",
        "        \"epoch\", \"lr\",\n",
        "        \"train_loss\", \"train_ce\", \"train_dice_loss\",\n",
        "        \"train_macro_dice\", \"train_macro_jac\", \"train_macro_hd95\",\n",
        "        \"test_loss\", \"test_ce\", \"test_dice_loss\",\n",
        "        \"test_macro_dice\", \"test_macro_jac\", \"test_macro_hd95\",\n",
        "    ]\n",
        "    for c in range(1, C):\n",
        "        header_cols += [\n",
        "            f\"train_dice_c{c:02d}\", f\"train_jac_c{c:02d}\", f\"train_hd95_c{c:02d}\",\n",
        "            f\"test_dice_c{c:02d}\",  f\"test_jac_c{c:02d}\",  f\"test_hd95_c{c:02d}\",\n",
        "        ]\n",
        "    header = \",\".join(header_cols) + \"\\n\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    torch.manual_seed(opts.random_seed)\n",
        "    np.random.seed(opts.random_seed)\n",
        "    random.seed(opts.random_seed)\n",
        "\n",
        "    tr_transform = RandomGenerator(output_size=[opts.img_size, opts.img_size])\n",
        "\n",
        "    train_dataset = Synapse_dataset(\n",
        "        versions_root=opts.versions_root,\n",
        "        split=\"train\",\n",
        "        transform=tr_transform,\n",
        "        list_dir=opts.list_dir,\n",
        "        data_subdir=opts.data_subdir,\n",
        "        train_folder=opts.train_folder,\n",
        "        test_folder=opts.test_folder,\n",
        "        verbose=True,\n",
        "    )\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=opts.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    test_base = Synapse_dataset(\n",
        "        versions_root=opts.versions_root,\n",
        "        split=\"test\",\n",
        "        transform=None,\n",
        "        list_dir=opts.list_dir,\n",
        "        data_subdir=opts.data_subdir,\n",
        "        train_folder=opts.train_folder,\n",
        "        test_folder=opts.test_folder,\n",
        "        verbose=True,\n",
        "    )\n",
        "    print(\"Test cases:\", len(test_base))\n",
        "\n",
        "    test_dataset = TestVol2DSliceDataset(test_base)\n",
        "    print(\"Test slices (2D):\", len(test_dataset))\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=opts.test_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    model = AttU_Net(img_ch=3, num_class=C).to(device)\n",
        "\n",
        "    last_path = os.path.join(ckpt_dir, \"AttUNet_last.pth\")\n",
        "    best_path = os.path.join(ckpt_dir, \"AttUNet_best.pth\")\n",
        "\n",
        "    if opts.RESUME and os.path.isfile(last_path):\n",
        "        print(\"Loading AttUNet checkpoint:\", last_path)\n",
        "        model.load_state_dict(torch.load(last_path, map_location=device), strict=True)\n",
        "\n",
        "    ce_w, counts = estimate_ce_weights_from_loader(\n",
        "        train_loader, C, device,\n",
        "        max_batches=opts.ce_weight_batches,\n",
        "        clamp_min=opts.ce_w_min,\n",
        "        clamp_max=opts.ce_w_max,\n",
        "    )\n",
        "    print(\"Pixel counts:\", counts.cpu().numpy().astype(np.int64))\n",
        "    print(\"CE weights:\", ce_w.detach().cpu().numpy())\n",
        "\n",
        "    ce_loss = nn.CrossEntropyLoss(weight=ce_w, reduction=\"mean\")\n",
        "    dice_w = estimate_dice_weights_from_ce_weights(ce_w)\n",
        "    dice_loss = MultiClassDiceLoss(class_weights=dice_w, include_background=False)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=opts.LR, weight_decay=opts.weight_decay)\n",
        "\n",
        "    best_score = -1e9 if opts.save_best_on == \"macro_dice\" else 1e9\n",
        "\n",
        "    def _fmt(x):\n",
        "        return \"\" if (x is None or (isinstance(x, float) and np.isnan(x))) else f\"{x}\"\n",
        "\n",
        "    for epoch in range(opts.START_EPOCH, opts.NB_EPOCH):\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(f\"Epoch {epoch}/{opts.NB_EPOCH-1} | lr={lr:.6g} | AttU-Net\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        model.train()\n",
        "        running_train = init_running_metrics(C)\n",
        "\n",
        "        loss_sum = 0.0\n",
        "        ce_sum = 0.0\n",
        "        dice_sum = 0.0\n",
        "        n_batches = 0\n",
        "\n",
        "        for i, samples in tqdm(enumerate(train_loader), total=len(train_loader), desc=\"TRAIN\"):\n",
        "            images = samples[\"image\"]\n",
        "            labels = samples[\"label\"]\n",
        "\n",
        "            if images.size(1) == 1:\n",
        "                images = images.repeat(1, 3, 1, 1)\n",
        "\n",
        "            imgs = images.to(device, dtype=torch.float32, non_blocking=True)\n",
        "            gts = labels.to(device, dtype=torch.long, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            logits = model(imgs)\n",
        "\n",
        "            loss_ce = ce_loss(logits, gts)\n",
        "            loss_d = dice_loss(logits, gts)\n",
        "            loss = loss_ce + loss_d\n",
        "\n",
        "            loss.backward()\n",
        "            if opts.grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), opts.grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_sum += float(loss.detach().cpu())\n",
        "            ce_sum += float(loss_ce.detach().cpu())\n",
        "            dice_sum += float(loss_d.detach().cpu())\n",
        "            n_batches += 1\n",
        "\n",
        "            if i % 20 == 0:\n",
        "                print(f\"[batch {i:04d}] loss={loss.item():.4f} | ce={loss_ce.item():.4f} | dice={loss_d.item():.4f}\")\n",
        "\n",
        "            if opts.metrics_every > 0 and (i % opts.metrics_every == 0):\n",
        "                with torch.no_grad():\n",
        "                    pred = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
        "                    pred_np = pred.detach().cpu().numpy()\n",
        "                    gt_np = gts.detach().cpu().numpy()\n",
        "                    for b in range(pred_np.shape[0]):\n",
        "                        running_train = update_running_metrics(running_train, pred_np[b], gt_np[b], C)\n",
        "\n",
        "        train_loss = loss_sum / max(1, n_batches)\n",
        "        train_ce = ce_sum / max(1, n_batches)\n",
        "        train_dice_l = dice_sum / max(1, n_batches)\n",
        "\n",
        "        train_per_class, train_macro = finalize_metrics(running_train, C)\n",
        "        tr_macro_dice, tr_macro_jac, tr_macro_hd95 = train_macro\n",
        "\n",
        "        print(\"\\n--- Train Summary ---\")\n",
        "        print(f\"[TRAIN] Loss={train_loss:.6f} | CE={train_ce:.6f} | DiceLoss={train_dice_l:.6f}\")\n",
        "        print(f\"[TRAIN] Macro Dice={tr_macro_dice:.4f} | Jaccard={tr_macro_jac:.4f} | HD95={tr_macro_hd95:.4f}\")\n",
        "\n",
        "        test_per_class, test_macro, test_losses = evaluate_on_test_2d(\n",
        "            model, test_loader, C, opts.img_size, device, ce_loss, dice_loss\n",
        "        )\n",
        "        te_macro_dice, te_macro_jac, te_macro_hd95 = test_macro\n",
        "        test_loss, test_ce, test_dice_l = test_losses\n",
        "\n",
        "        print(\"\\n--- Test Summary (2D slices from test_vol) ---\")\n",
        "        print(f\"[TEST] Loss={test_loss:.6f} | CE={test_ce:.6f} | DiceLoss={test_dice_l:.6f}\")\n",
        "        print(f\"[TEST] Macro Dice={te_macro_dice:.4f} | Jaccard={te_macro_jac:.4f} | HD95={te_macro_hd95:.4f}\")\n",
        "\n",
        "        torch.save(model.state_dict(), last_path)\n",
        "        print(\"✅ Saved AttUNet last checkpoint:\", last_path)\n",
        "\n",
        "        row = [\n",
        "            str(epoch), f\"{lr}\",\n",
        "            f\"{train_loss}\", f\"{train_ce}\", f\"{train_dice_l}\",\n",
        "            _fmt(tr_macro_dice), _fmt(tr_macro_jac), _fmt(tr_macro_hd95),\n",
        "            f\"{test_loss}\", f\"{test_ce}\", f\"{test_dice_l}\",\n",
        "            _fmt(te_macro_dice), _fmt(te_macro_jac), _fmt(te_macro_hd95),\n",
        "        ]\n",
        "        for c in range(1, C):\n",
        "            td, tj, th = train_per_class[c]\n",
        "            vd, vj, vh = test_per_class[c]\n",
        "            row += [_fmt(td), _fmt(tj), _fmt(th), _fmt(vd), _fmt(vj), _fmt(vh)]\n",
        "\n",
        "        append_csv(csv_path, header, \",\".join(row) + \"\\n\")\n",
        "\n",
        "        if opts.save_best_on == \"macro_dice\":\n",
        "            score = te_macro_dice\n",
        "            if (not np.isnan(score)) and score > best_score:\n",
        "                best_score = score\n",
        "                torch.save(model.state_dict(), best_path)\n",
        "                print(f\"✅ Saved AttUNet best checkpoint (test_macro_dice={best_score:.4f}):\", best_path)\n",
        "        else:\n",
        "            score = train_loss\n",
        "            if score < best_score:\n",
        "                best_score = score\n",
        "                torch.save(model.state_dict(), best_path)\n",
        "                print(f\"✅ Saved AttUNet best checkpoint (train_loss={best_score:.6f}):\", best_path)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Done.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kztVkawXM34j",
        "outputId": "d0542a61-671e-4066-b02d-81372f724c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN: 100%|██████████| 553/553 [02:57<00:00,  3.12it/s]\n",
            "TEST_2D: 100%|██████████| 196/196 [02:54<00:00,  1.12it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:55<00:00,  3.15it/s]\n",
            "TEST_2D: 100%|██████████| 196/196 [02:57<00:00,  1.10it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:56<00:00,  3.13it/s]\n",
            "TEST_2D: 100%|██████████| 196/196 [02:54<00:00,  1.12it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:56<00:00,  3.13it/s]\n",
            "TEST_2D: 100%|██████████| 196/196 [02:52<00:00,  1.14it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:56<00:00,  3.13it/s]\n",
            "TEST_2D: 100%|██████████| 196/196 [02:54<00:00,  1.12it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:56<00:00,  3.12it/s]\n",
            "TEST_2D: 100%|██████████| 196/196 [03:00<00:00,  1.09it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:56<00:00,  3.13it/s]\n",
            "TEST_2D: 100%|██████████| 196/196 [02:56<00:00,  1.11it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:57<00:00,  3.12it/s]\n",
            "TEST_2D: 100%|██████████| 196/196 [02:55<00:00,  1.11it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:56<00:00,  3.13it/s]\n",
            "TEST_2D: 100%|██████████| 196/196 [02:58<00:00,  1.10it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:57<00:00,  3.12it/s]\n",
            "TEST_2D: 100%|██████████| 196/196 [03:01<00:00,  1.08it/s]\n",
            "TRAIN: 100%|██████████| 553/553 [02:56<00:00,  3.13it/s]\n",
            "TEST_2D:  61%|██████    | 119/196 [01:48<01:25,  1.11s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# debugging"
      ],
      "metadata": {
        "id": "sM7xVuVBfOZq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FxJtatFEfSjD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}